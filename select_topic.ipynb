{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tomotopy as tp\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "순위         0\n",
       "영화명        0\n",
       "개봉일        0\n",
       "매출액        0\n",
       "매출액 점유율    0\n",
       "관객수        0\n",
       "스크린수       0\n",
       "대표국적       0\n",
       "국적         0\n",
       "배급사        0\n",
       "줄거리        0\n",
       "장르         0\n",
       "줄거리2       0\n",
       "흥행여부       0\n",
       "명사         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"2014_2023_ForeignMovie_summary_preprocess_top_bottom\"\n",
    "data = pd.read_csv(data_name+\".csv\")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"순위\", \"영화명\", \"개봉일\", \"대표국적\", \"줄거리\", \"장르\", \"줄거리2\", \"명사\", \"흥행여부\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>영화명</th>\n",
       "      <th>개봉일</th>\n",
       "      <th>대표국적</th>\n",
       "      <th>줄거리</th>\n",
       "      <th>장르</th>\n",
       "      <th>줄거리2</th>\n",
       "      <th>명사</th>\n",
       "      <th>흥행여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>겨울왕국</td>\n",
       "      <td>2014-01-16</td>\n",
       "      <td>미국</td>\n",
       "      <td>얼어붙은 세상을 녹일 자매가 온다!  서로가 최고의 친구였던 자매 ‘엘사’와 ‘안나...</td>\n",
       "      <td>애니메이션,어드벤처,가족,코미디,뮤지컬,판타지</td>\n",
       "      <td>얼어붙은 세상을 녹일 자매가 온다  서로가 최고의 친구였던 자매 엘사와 안나 하지만...</td>\n",
       "      <td>세상,자매,서로,최고,친구,자매,엘사,언니,엘사,동생,말,비밀,신비,힘,그것,엘사,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>인터스텔라</td>\n",
       "      <td>2014-11-06</td>\n",
       "      <td>미국</td>\n",
       "      <td>“우린 답을 찾을 거야, 늘 그랬듯이” 세계 각국의 정부와 경제가 완전히 붕괴된 미...</td>\n",
       "      <td>SF</td>\n",
       "      <td>우린 답을 찾을 거야 늘 그랬듯이 세계 각국의 정부와 경제가 완전히 붕괴된 미래가 ...</td>\n",
       "      <td>우리,답,세계,각국,정부,경제,붕괴,미래,세기,잘못,세계,식량,부족,해체,이때,시공...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>트랜스포머: 사라진 시대</td>\n",
       "      <td>2014-06-25</td>\n",
       "      <td>미국</td>\n",
       "      <td>트랜스포머의 시대는 끝났다!  시카고에서 벌어진 오토봇과 디셉티콘의 전투로 인해 수...</td>\n",
       "      <td>액션,SF,어드벤처</td>\n",
       "      <td>트랜스포머의 시대는 끝났다  시카고에서 벌어진 오토봇과 디셉티콘의 전투로 인해 수많...</td>\n",
       "      <td>트랜스포머,시대,시카고,오토봇,디셉티콘,전투,사상자,발생,도시,파괴,정부,일부,오토...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   순위            영화명         개봉일 대표국적  \\\n",
       "0   1           겨울왕국  2014-01-16   미국   \n",
       "1   2          인터스텔라  2014-11-06   미국   \n",
       "2   3  트랜스포머: 사라진 시대  2014-06-25   미국   \n",
       "\n",
       "                                                 줄거리  \\\n",
       "0  얼어붙은 세상을 녹일 자매가 온다!  서로가 최고의 친구였던 자매 ‘엘사’와 ‘안나...   \n",
       "1  “우린 답을 찾을 거야, 늘 그랬듯이” 세계 각국의 정부와 경제가 완전히 붕괴된 미...   \n",
       "2  트랜스포머의 시대는 끝났다!  시카고에서 벌어진 오토봇과 디셉티콘의 전투로 인해 수...   \n",
       "\n",
       "                          장르  \\\n",
       "0  애니메이션,어드벤처,가족,코미디,뮤지컬,판타지   \n",
       "1                         SF   \n",
       "2                 액션,SF,어드벤처   \n",
       "\n",
       "                                                줄거리2  \\\n",
       "0  얼어붙은 세상을 녹일 자매가 온다  서로가 최고의 친구였던 자매 엘사와 안나 하지만...   \n",
       "1  우린 답을 찾을 거야 늘 그랬듯이 세계 각국의 정부와 경제가 완전히 붕괴된 미래가 ...   \n",
       "2  트랜스포머의 시대는 끝났다  시카고에서 벌어진 오토봇과 디셉티콘의 전투로 인해 수많...   \n",
       "\n",
       "                                                  명사  흥행여부  \n",
       "0  세상,자매,서로,최고,친구,자매,엘사,언니,엘사,동생,말,비밀,신비,힘,그것,엘사,...     1  \n",
       "1  우리,답,세계,각국,정부,경제,붕괴,미래,세기,잘못,세계,식량,부족,해체,이때,시공...     1  \n",
       "2  트랜스포머,시대,시카고,오토봇,디셉티콘,전투,사상자,발생,도시,파괴,정부,일부,오토...     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6718/6718 [00:00<00:00, 142543.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6718/6718 [00:00<00:00, 49856.03it/s]\n"
     ]
    }
   ],
   "source": [
    "data[\"명사\"] = data[\"명사\"].progress_map(lambda x:x.split(\",\"))\n",
    "data[\"명사\"] = data[\"명사\"].progress_map(lambda x:[s for s in x if len(s) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = data[\"명사\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count = collections.Counter(total_words)\n",
    "words_count = dict(words_count)\n",
    "words_count = sorted(words_count.items(), key=lambda x:x[1], reverse=True)\n",
    "len(words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(data, column, min_count, min_number):\n",
    "    stopwords = []\n",
    "    for word, value in words_count:  # minimum of occuring for one word in all documents\n",
    "        if value <= min_count:\n",
    "            stopwords.append(word)\n",
    "    \n",
    "    data[column] = data[column].progress_map(lambda x:[w for w in x if w not in stopwords])\n",
    "    data[\"단어개수\"] = data[column].apply(lambda x:len(x))\n",
    "\n",
    "    data = data[data[\"단어개수\"] >= min_number]  # minimum of number of total words in one document\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(k, iteration, text, word_remove=0):\n",
    "    model = tp.LDAModel(k=k, rm_top=word_remove, seed=42)\n",
    "    \n",
    "    for line in text:\n",
    "        line = str(line).split(\",\")\n",
    "        model.add_doc(line)\n",
    "    \n",
    "    model.burn_in = 100\n",
    "    model.train(0)\n",
    "    \n",
    "    # print(f\"토픽 개수: {k}, 문서 개수: {len(model.docs)}, 단어 개수:, {len(model.used_vocabs)}, 단어의 총수: {model.num_words}\")\n",
    "    # print(f\"제거된 단어들: {model.removed_top_words}\")\n",
    "    \n",
    "    # print(\"훈련 중...\",flush=True)\n",
    "    for i in range(0, iteration, 10):\n",
    "        model.train(10)\n",
    "\n",
    "    #model.summary()\n",
    "    return(model, model.ll_per_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [x for x in range(2, 31, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplex_coherence_graph(data, column):\n",
    "  perco_df = pd.DataFrame(columns=[\"k\", \"perplexity\", \"coherence\"])\n",
    "  for k in k_list:\n",
    "    print(f\"---training for k: {k}---\")\n",
    "    min_dict = {}\n",
    "    for min_count in range(5, 30, 5):  # min_count range\n",
    "      for min_number in range(10, 30, 5):  # min_number range\n",
    "        print(f\"---training for min_count: {min_count}, min_number: {min_number}---\")\n",
    "        key_name = f\"{min_count}_{min_number}\"\n",
    "\n",
    "        data = filter_words(data, column, min_count, min_number)\n",
    "        if len(data) < 100:\n",
    "          continue\n",
    "\n",
    "        model, log_score = lda(k=k, iteration=1000, text=data[column])\n",
    "        min_dict[key_name] = log_score\n",
    "        model_name = f\"model_{min_count}_{min_number}\"\n",
    "        model.save(f\"./tmp_model/{model_name}.bin\")\n",
    "    \n",
    "    min_key = min(min_dict, key=min_dict.get)\n",
    "    min_key = str(min_key)\n",
    "    min_list = min_key.split(\"_\")\n",
    "    min_list = [x for x in min_list]\n",
    "    \n",
    "    print(f\"word_Mean: {np.array(data['단어개수']).mean()}, word_Median: {np.median(np.array(data['단어개수']))}\")\n",
    "    print(f\"---find minimum log-likelihood\", end=\"\")\n",
    "    optimal_model_name = f\"model_{min_list[0]}_{min_list[1]}\"\n",
    "    model.load(f\"./tmp_model/{optimal_model_name}.bin\")\n",
    "    print(f\": {model.ll_per_word}---\")\n",
    "\n",
    "    for file in os.scandir(\"./tmp_model/\"):  # remove all model files\n",
    "      os.remove(file.path)\n",
    "    model.save(f\"./tmp_model/topic-{k}_model.bin\")  # only save optimal model for each number of topic\n",
    "\n",
    "    perplexity_score = model.perplexity\n",
    "          \n",
    "    coh = tp.coherence.Coherence(model, coherence=\"u_mass\")\n",
    "    coherence_score = coh.get_score()\n",
    "\n",
    "    tmp = [[k, perplexity_score, coherence_score]]\n",
    "    tmp_df = pd.DataFrame(tmp, columns=[\"k\", \"perplexity\", \"coherence\"])\n",
    "    perco_df = pd.concat([perco_df, tmp_df], ignore_index=True)\n",
    "  perco_df = perco_df.reset_index()\n",
    "  perco_df = perco_df.drop(\"index\", axis=1)\n",
    "\n",
    "  fig, ax = plt.subplots(1, 2)\n",
    "  sns.lineplot(x=\"k\", y=\"perplexity\", data=perco_df, ax=ax[0])\n",
    "  sns.lineplot(x=\"k\", y=\"coherence\", data=perco_df, ax=ax[1])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_model(data, column, k):\n",
    "  model = lda(k, 1000, text=data[column])\n",
    "\n",
    "  topic = pd.DataFrame()\n",
    "  for i in range(k):\n",
    "    temp = pd.DataFrame()\n",
    "    temp = pd.DataFrame(model.get_topic_words(i, top_n=10))\n",
    "    temp.columns = [\"Topic\"+str(i),\"probs\"+str(i)]\n",
    "    temp = temp.reset_index()\n",
    "    if (i==0):\n",
    "        topic = pd.concat([topic, temp], ignore_index=True)\n",
    "    else:\n",
    "        topic = topic.merge(temp, left_on=\"index\", right_on=\"index\")\n",
    "\n",
    "  new = pd.DataFrame()\n",
    "  for line in model.docs:\n",
    "      temp = pd.DataFrame(line.get_topic_dist()).T\n",
    "      new = pd.concat([new, temp])\n",
    "\n",
    "  new.columns = [\"Topic\"+ str(x) for x in range(k)]\n",
    "  new = new.reset_index().drop([\"index\"], axis=1)\n",
    "  raw = data.reset_index().drop([\"index\"], axis=1)\n",
    "  data_df = raw.merge(new, left_index=True, right_index=True)\n",
    "  data_df[\"Highest_Topic\"]=data_df[[\"Topic\"+ str(s) for s in range(k)]].idxmax(axis=1)\n",
    "\n",
    "  for i in range(k):\n",
    "    print(f\"--Topic{str(i)}--\")\n",
    "    count = len(data_df[data_df[\"Highest_Topic\"]==\"Topic\"+str(i)])\n",
    "    print(f\"토픽 개수 : {count:8}, 전체 퍼센트 : {count/len(raw)*100:8.3f}\")\n",
    "    print(topic[\"Topic\"+str(i)])\n",
    "    print(data_df[data_df[\"Highest_Topic\"]==\"Topic\"+str(i)][\"줄거리\"].sample(n=min(5, count)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex_coherence_graph(data, \"명사\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
